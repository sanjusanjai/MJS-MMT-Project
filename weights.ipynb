{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from data_v1 import make_data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "# from data_v2 import make_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class SVM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVM, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 15)\n",
    "        self.fc2 = nn.Linear(15, 28)\n",
    "        # self.fc3 = nn.Linear()\n",
    "        self.fc4 = nn.Linear(28, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        # x = torch.relu(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(batch_size=32, val_split=0.1):\n",
    "    x_train, y_train, x_test, y_test = make_data()\n",
    "\n",
    "    # Scale the input data using the standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    x_train_normalized = torch.tensor(scaler.fit_transform(x_train), dtype=torch.float)\n",
    "    x_test_normalized = torch.tensor(scaler.transform(x_test), dtype=torch.float)\n",
    "\n",
    "    # Split the training data into training and validation sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train_split, x_val_split, y_train_split, y_val_split = train_test_split(\n",
    "        x_train_normalized, y_train, test_size=val_split, random_state=42)\n",
    "\n",
    "    # Combine the input and target data into tuples\n",
    "    train_data = [(x_train_split[i], y_train_split[i]) for i in range(len(x_train_split))]\n",
    "    val_data = [(x_val_split[i], y_val_split[i]) for i in range(len(x_val_split))]\n",
    "    test_data = [(x_test_normalized[i], y_test[i]) for i in range(len(x_test))]\n",
    "\n",
    "    # Create DataLoader objects for the train, validation, and test data\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    valloader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return trainloader, valloader, testloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs=100\n",
    "lr=0.001\n",
    "# get the trainloader and testloader\n",
    "\n",
    "\n",
    "# print(trainloader.dataset[0][0].shape)\n",
    "# Initialize the network\n",
    "# net = SVM()\n",
    "    # net = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    \n",
    "    # Initialize the network\n",
    "    net = SVM()\n",
    "    trainloader, validloader, testloader = preprocess_data()\n",
    "\n",
    "    # net = MLP()\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    train_losses, valid_losses = [], []\n",
    "    for epoch in range(epochs):\n",
    "        running_train_loss, running_valid_loss = 0.0, 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            labels = labels.unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            # print(inputs.shape)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "        # Compute validation loss\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                inputs, labels = data\n",
    "                labels = labels.unsqueeze(1)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "                running_valid_loss += loss.item()\n",
    "\n",
    "        train_loss = running_train_loss / len(trainloader)\n",
    "        valid_loss = running_valid_loss / len(validloader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        # print(f\"Epoch {epoch+1}, train loss: {train_loss:.3f}, valid loss: {valid_loss:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Test the model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            labels = labels.unsqueeze(1)\n",
    "            outputs = net(inputs)\n",
    "            predicted = (outputs >= 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.float()).sum().item()\n",
    "\n",
    "    print(f\"Accuracy: {100 * correct/total:.2f}%\")\n",
    "\n",
    "    # # Plot the training and validation loss\n",
    "    # plt.plot(train_losses, label='Training Loss')\n",
    "    # plt.plot(valid_losses, label='Validation Loss')\n",
    "    # plt.legend()\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.show()\n",
    "    # print(net)\n",
    "    return net,100 * correct/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.98%\n",
      "Accuracy: 53.92%\n",
      "Accuracy: 57.84%\n",
      "Accuracy: 47.06%\n",
      "Accuracy: 54.90%\n",
      "Accuracy: 50.00%\n",
      "Accuracy: 50.00%\n",
      "Accuracy: 55.88%\n",
      "Accuracy: 39.22%\n",
      "Accuracy: 56.86%\n",
      "Accuracy: 49.02%\n",
      "Accuracy: 50.98%\n",
      "Accuracy: 67.65%\n",
      "67.6470588235294\n"
     ]
    }
   ],
   "source": [
    "acc=0\n",
    "while acc<65:\n",
    "\tmodel,acc=main()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVM(\n",
       "  (fc1): Linear(in_features=10, out_features=15, bias=True)\n",
       "  (fc2): Linear(in_features=15, out_features=28, bias=True)\n",
       "  (fc4): Linear(in_features=28, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model_weights.pth to model\n",
    "model.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9516e-02, -3.3753e-01,  5.8118e-01,  2.0415e-02,  1.4470e-02,\n",
      "         -3.8823e-01, -1.1727e-01,  6.1753e-02, -2.7958e-01,  4.9132e-01],\n",
      "        [-1.7975e-01,  3.7013e-01,  4.2969e-01,  1.7226e-01,  3.1475e-01,\n",
      "         -2.7447e-01, -3.7376e-02,  3.2705e-01,  1.2583e-01, -3.9519e-01],\n",
      "        [-3.9365e-01,  3.3264e-01, -5.5171e-01, -2.4816e-01, -2.1076e-01,\n",
      "         -2.0186e-01,  2.2691e-01, -1.7791e-01, -2.4108e-02, -1.9747e-01],\n",
      "        [-2.7754e-01, -3.0423e-01, -4.0497e-01,  2.6573e-02,  6.8814e-02,\n",
      "         -5.5686e-01, -3.7652e-01, -1.2137e-01, -1.6779e-01, -4.0862e-01],\n",
      "        [ 3.3685e-01, -1.5504e-02, -2.3073e-01,  1.6293e-01, -2.8569e-01,\n",
      "          3.1163e-01, -3.4972e-01, -9.9787e-02,  1.0516e-01, -4.2642e-01],\n",
      "        [-2.2154e-01,  3.3974e-02,  1.2887e-01,  2.2012e-01, -2.3108e-01,\n",
      "         -3.6749e-01, -1.1576e-01, -7.3861e-01,  1.5479e-01,  2.7720e-01],\n",
      "        [ 2.4090e-01,  1.8826e-01, -6.4668e-02, -1.4563e-01,  3.7702e-01,\n",
      "         -3.8505e-01,  2.4096e-01,  6.9786e-01, -1.3161e-01,  3.8014e-02],\n",
      "        [-9.3586e-02, -2.9838e-01,  1.3522e-01, -3.8705e-01, -3.0571e-01,\n",
      "          3.5653e-01,  3.6584e-01, -4.5960e-01, -3.3421e-01, -5.2108e-01],\n",
      "        [ 1.4637e-01,  3.1698e-01, -1.7713e-01,  4.6152e-01,  1.1110e-01,\n",
      "         -6.2386e-02, -2.2653e-01, -4.0266e-01, -3.0488e-01,  1.5865e-01],\n",
      "        [ 5.0610e-01,  1.3740e-01, -4.5237e-01, -2.3080e-01, -7.2333e-04,\n",
      "         -2.9999e-01, -4.4448e-02,  1.4178e-01,  2.9326e-01,  4.6879e-01],\n",
      "        [-1.2442e-02, -6.0054e-01, -1.5058e-01,  2.8837e-01, -2.9957e-01,\n",
      "          1.1970e-01, -2.7192e-01,  1.8363e-01, -2.4680e-01,  2.9985e-01],\n",
      "        [ 1.9246e-01,  2.8818e-01, -3.8736e-01,  4.0271e-01, -2.6948e-01,\n",
      "         -3.0672e-02,  1.9840e-01, -3.2661e-01, -2.3550e-01, -1.4443e-01],\n",
      "        [-9.9465e-02,  6.6972e-03, -9.5444e-02,  6.5882e-01, -1.8625e-01,\n",
      "          1.8961e-01, -3.1315e-02, -7.9099e-02, -4.2756e-01, -1.8555e-01],\n",
      "        [ 1.5020e-02, -1.7312e-01,  4.7263e-01,  6.2072e-01, -2.8587e-01,\n",
      "         -1.3055e-02,  2.2563e-01,  1.2346e-02,  1.0609e-02, -1.1679e-01],\n",
      "        [-2.3569e-01,  9.5562e-02, -3.0314e-01, -5.9410e-01,  3.4936e-01,\n",
      "          1.6309e-01, -9.0182e-02, -1.9138e-01,  1.0564e-01,  1.0339e-01]])\n",
      "tensor([[ 0.1995, -0.4400,  0.2768,  0.2589,  0.0633,  0.0115, -0.8252,  0.0297,\n",
      "          0.2061,  0.0613, -0.3634,  0.1307, -0.2601, -0.6410, -0.2027],\n",
      "        [ 0.1272,  0.1799, -0.4161,  0.0215,  0.4225, -0.4257,  0.0553, -0.2795,\n",
      "          0.0402, -0.1730, -0.1132, -0.0786,  0.2528, -0.1106, -0.2527],\n",
      "        [-0.6056,  0.2579,  0.3490,  0.3769,  0.0795,  0.1802,  0.1114,  0.0232,\n",
      "         -0.3429, -0.3300,  0.3808,  0.1806, -0.1912,  0.0256,  0.2084],\n",
      "        [-0.2435, -0.2205, -0.0091,  0.2504,  0.1501, -0.0392, -0.2147, -0.0819,\n",
      "         -0.2319, -0.0164, -0.1063, -0.1181, -0.2131, -0.0684,  0.0400],\n",
      "        [ 0.0205, -0.1261,  0.0185, -0.0066,  0.1629,  0.1350, -0.2479, -0.2421,\n",
      "          0.1971,  0.1744,  0.1141, -0.0044,  0.1675,  0.1151,  0.3387],\n",
      "        [-0.1667, -0.1635, -0.2412, -0.0573, -0.1634,  0.1008, -0.1438,  0.0401,\n",
      "         -0.2505,  0.1048,  0.0613,  0.0982,  0.1055, -0.0978, -0.2091],\n",
      "        [ 0.0924,  0.3400,  0.1147,  0.2665,  0.0897, -0.3697, -0.0405, -0.3899,\n",
      "          0.1727,  0.0785, -0.0147, -0.2209,  0.1569,  0.2140,  0.2415],\n",
      "        [-0.1684,  0.2690, -0.1015, -0.4045, -0.1364, -0.1638, -0.2526,  0.2357,\n",
      "          0.0707, -0.1970, -0.3913, -0.2006, -0.0616,  0.2329,  0.3373],\n",
      "        [ 0.3803, -0.2502, -0.3936, -0.7093,  0.1558,  0.0339,  0.0077,  0.1179,\n",
      "          0.3288, -0.1240,  0.0461,  0.0846, -0.5410,  0.5136,  0.0394],\n",
      "        [ 0.2591,  0.0040,  0.1866, -0.3238, -0.8282,  0.0695,  0.3192, -0.5158,\n",
      "         -0.0384, -0.1284, -0.5689, -0.5937, -0.4882, -0.3337, -0.4902],\n",
      "        [-0.2639,  0.1679, -0.3445, -0.3937,  0.0247,  0.3830,  0.4010, -0.4615,\n",
      "          0.3376,  0.1794, -0.1548, -0.0116, -0.3515,  0.2363, -0.3048],\n",
      "        [ 0.0862, -0.2242,  0.0304,  0.0589, -0.5110,  0.0945,  0.4308,  0.2767,\n",
      "         -0.6940, -0.3467,  0.2444,  0.1222, -0.0652, -0.2029,  0.4510],\n",
      "        [-0.1685,  0.1814,  0.2447, -0.2392, -0.3787,  0.4535, -0.1020,  0.0681,\n",
      "         -0.2116, -0.2870, -0.4226,  0.0688,  0.2328,  0.0920,  0.5471],\n",
      "        [-0.0192, -0.1289, -0.3950, -0.1601,  0.0402,  0.1174, -0.1070,  0.1639,\n",
      "          0.0892,  0.0819,  0.0370,  0.0855,  0.1982,  0.0105,  0.2119],\n",
      "        [ 0.2691, -0.2091,  0.2830, -0.6442,  0.0146,  0.1405, -0.1931, -0.2035,\n",
      "         -0.1533, -0.1232, -0.1043, -0.0199, -0.1057,  0.0790,  0.2636],\n",
      "        [ 0.2016, -0.2935, -0.1409,  0.0689,  0.6442, -0.2233, -0.1339,  0.2925,\n",
      "         -0.0059, -0.8077, -0.3059, -0.1514, -0.2858, -0.3049,  0.0204],\n",
      "        [-0.0918, -0.2098,  0.2656,  0.5454, -0.3274, -0.6431, -0.1524, -0.6990,\n",
      "         -0.1874,  0.2537, -0.0321, -0.0567,  0.1001,  0.0501,  0.4807],\n",
      "        [ 0.4141, -0.4464,  0.0646,  0.3195,  0.1925,  0.0473,  0.2350, -0.1059,\n",
      "         -0.0060, -0.0697, -0.2538,  0.1042,  0.1439, -0.2516, -0.3426],\n",
      "        [-0.1603,  0.0702,  0.2778, -0.1924,  0.2503,  0.2352,  0.5151,  0.2467,\n",
      "         -0.2757,  0.2216,  0.4266,  0.2910,  0.0754,  0.0294,  0.2668],\n",
      "        [-0.1170,  0.2653,  0.2090, -0.0712, -0.2812, -0.4364, -0.2065, -0.0373,\n",
      "          0.0140,  0.1731, -0.1433, -0.2707,  0.1464,  0.1478,  0.1816],\n",
      "        [ 0.2272,  0.2920,  0.2512,  0.0750,  0.4913, -0.1441, -0.0247,  0.1437,\n",
      "          0.1832, -0.3144, -0.2609,  0.2540, -0.2392, -0.9114, -0.4746],\n",
      "        [-0.3456,  0.3279,  0.1766, -0.8785,  0.1746, -0.3872, -0.4189,  0.1813,\n",
      "         -0.1521,  0.1489, -0.2287, -0.3519, -0.1349,  0.4885, -0.1570],\n",
      "        [ 0.2668, -0.8103,  0.0362,  0.0768,  0.1624,  0.3194, -0.3002,  0.3417,\n",
      "          0.1836, -0.0740, -0.4486, -0.3119, -0.0936,  0.0675, -0.8785],\n",
      "        [ 0.4155, -0.1392,  0.2147, -0.3075, -0.7161,  0.0901, -0.5458, -0.2309,\n",
      "         -0.5013, -0.4405,  0.5589,  0.1496,  0.1568,  0.0688, -0.2226],\n",
      "        [ 0.2947,  0.1603,  0.1042,  0.1655,  0.3160,  0.0481,  0.0881,  0.0755,\n",
      "          0.2539, -0.1282, -0.1051, -0.0548,  0.2989, -0.0723, -0.5025],\n",
      "        [ 0.2838,  0.3058,  0.0523,  0.1155,  0.4568,  0.0027,  0.0860,  0.2926,\n",
      "          0.1240, -0.2151, -0.3035, -0.1372,  0.1038,  0.1125, -0.7492],\n",
      "        [-0.0295, -0.3249, -0.3526,  0.2358,  0.0450,  0.2750, -0.1274, -0.2615,\n",
      "          0.1373,  0.1865, -0.0596,  0.1649,  0.1330,  0.0846,  0.3809],\n",
      "        [ 0.1960,  0.1250,  0.4304, -0.0571, -0.3916, -0.4078,  0.2215, -0.0081,\n",
      "         -0.2203, -0.1310, -0.3023, -0.0472, -0.2153, -0.5346, -0.5013]])\n",
      "tensor([[ 0.6239,  0.5965, -0.3343,  0.0970,  0.1474, -0.0520,  0.3348,  0.5052,\n",
      "         -0.8645,  0.5038, -0.7629, -0.4284, -0.4422,  0.1695, -0.6448,  1.0145,\n",
      "          0.8539,  0.3106, -0.4531,  0.6479,  0.7019,  1.0929,  0.5578, -0.7053,\n",
      "          0.2094,  0.3076,  0.4274,  0.5064]])\n"
     ]
    }
   ],
   "source": [
    "# print weights of the model layer by layer\n",
    "# for param_tensor in model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "# print the weights of the first layer\n",
    "print(model.state_dict()['fc1.weight'])\n",
    "\n",
    "# print the weights of the second layer\n",
    "print(model.state_dict()['fc2.weight'])\n",
    "\n",
    "# print the weights of the third layer\n",
    "# print(model.state_dict()['fc3.weight'])\n",
    "\n",
    "# print the weights of the fourth layer\n",
    "print(model.state_dict()['fc4.weight'])\n",
    "\n",
    "# print the weights of the fifth layer\n",
    "# print(model.state_dict()['fc5.weight'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1\n",
      "fc2\n"
     ]
    }
   ],
   "source": [
    "# from the weights of the fc1 layer tell which features are important\n",
    "weight=model.state_dict()['fc1.weight']\n",
    "print(\"fc1\")\n",
    "fc1=[]\n",
    "# for each of the weight in weight print the index with the highest value\n",
    "for i in range(len(weight)):\n",
    "    # print(torch.argmax(weight[i]))\n",
    "    fc1.append(torch.argmax(weight[i]))\n",
    "\n",
    "    \n",
    "# from the weights of the fc2 layer tell which features are important\n",
    "weight=model.state_dict()['fc2.weight']\n",
    "fc2=[]\n",
    "print(\"fc2\")\n",
    "# for each of the weight in weight print the index with the highest value\n",
    "for i in range(len(weight)):\n",
    "    # print(torch.argmax(weight[i]))\n",
    "\tfc2.append(torch.argmax(weight[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1\n",
      "Counter({3: 4, 2: 2, 4: 2, 0: 2, 9: 2, 1: 1, 7: 1, 6: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# frequency of each feature in fc1\n",
    "print(\"fc1\")\n",
    "# for i in fc1:\n",
    "#     print(i.item(),end=\" \")\n",
    "print(Counter([i.item() for i in fc1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc2\n",
      "Counter({14: 6, 4: 5, 2: 3, 6: 3, 10: 2, 3: 2, 1: 2, 13: 2, 12: 1, 0: 1, 7: 1})\n"
     ]
    }
   ],
   "source": [
    "# frequency of each feature in fc2\n",
    "\n",
    "print(\"fc2\")\n",
    "print(Counter([i.item() for i in fc2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
